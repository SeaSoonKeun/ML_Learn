# encoding:utf-8import numpy as npfrom sklearn.cluster import KMeansimport matplotlib.pyplot as pltplt.figure(figsize=(12, 12))def loadDataSet(fileName):    '''         list集合    '''    dataMat = []    fr = open(fileName)    for line in fr.readlines():        curLine = line.strip().split('\t')        fltLine = list(map(float, curLine))        dataMat.append(fltLine)    return dataMatdef distEclud(vecA, vecB):    return np.sqrt(np.sum(np.power(vecA - vecB, 2)))'''    第一次选取3个中心点的坐标'''def randCent(dataSet, k):    # n是样本的维数,即列数    n = np.shape(dataSet)[1]    '''        centroids是一个3*2的矩阵，用于存储三个中心点的坐标        k行n列    '''    centroids = np.mat(np.zeros((k, n)))    # 遍历数据集的每一列    for j in range(n):        # 选取第j列的最小值        minJ = np.min(dataSet[:, j])        # 选取第j列的范围值        rangeJ = np.max(dataSet[:, j]) - minJ        # 生成k行1列的随机数，范围在minJ和minJ+rangeJ之间        centroids[:, j] = np.mat(minJ + rangeJ * np.random.rand(k, 1))    return centroids'''这段代码实现了k-means聚类算法。具体步骤如下：初始化簇分配结果矩阵clusterAssment，用于存储每个点的簇分配结果。初始化中心点centroids，通过调用createCent函数随机选择k个中心点。进入while循环，直到所有点的簇分配结果不再改变。遍历所有样本，计算每个样本点到所有中心点的距离，选择距离最近的中心点作为该样本点的簇分配结果。如果任一点的簇分配结果发生改变，则更新clusterChanged标志。将当前点的簇分配结果存入clusterAssment。遍历所有中心点，更新中心点的位置为该簇内所有样本点的均值。返回最终的中心点和簇分配结果。总结来说，该代码通过迭代计算每个样本点到中心点的距离，并将样本点分配到距离最近的簇中，然后更新中心点的位置为该簇内所有样本点的均值，直到所有点的簇分配结果不再改变。最终得到的中心点和簇分配结果可以用于聚类分析和可视化。'''def kMeans(dataSet, k, distMeas=distEclud, createCent=randCent):    # m是样本数    # np.shape(dataSet)[0]返回dataSet的行数    m = np.shape(dataSet)[0]    # np.mat(np.zeros((m, 2)))创建一个m*2的矩阵,m行2列,用于存储每个点的簇分配结果    clusterAssment = np.mat(np.zeros((m, 2)))    # createCent找到K个随机中心点,centroids是一个K*n的矩阵，存储K个中心点的坐标    centroids = createCent(dataSet, k)    clusterChanged = True    while clusterChanged:        clusterChanged = False        # 遍历所有样本（行数），i为行数，初始值为0，range()函数返回的是一个可迭代对象        for i in range(m):            # np.inf表示正无穷大            minDist = np.inf            minIndex = -1            # 遍历所有的中心点，j为个数，初始值为0            for j in range(k):                # centroids[j, :]表示取centroids的第j行数据                x = centroids[j, :]                # 计算点i到j的欧式距离，：表示所有列                distJI = distMeas(x, dataSet[i, :])                if distJI < minDist:                    minDist = distJI                    minIndex = j            # 如果任一点的簇分配结果发生改变，则更新clusterChanged标志            # clusterChanged = True 代表有簇分配结果发生改变            if clusterAssment[i, 0] != minIndex:                clusterChanged = True            # 并将当前点的簇分配结果存入clusterAssment            clusterAssment[i, :] = minIndex, minDist        '''        遍历所有的中心点，cent表示中心点的索引。        使用np.nonzero函数找到clusterAssment中第一列等于cent的索引值，即找到属于该簇的样本点的索引。        使用这些索引从dataSet中取出对应的样本点，存储在ptsInClust中。        使用np.mean函数计算ptsInClust中样本点的均值，axis=0表示按列计算均值。        将计算得到的均值作为新的中心点位置，更新centroids中第cent行的值。        通过这个过程，每个簇的中心点位置会根据簇内的样本点重新计算并更新。这样在下一次迭代中，样本点会被重新分配到更新后的中心点附近，从而逐步优化聚类结果。        '''        for cent in range(k):            ptsInClust = dataSet[np.nonzero(clusterAssment[:, 0].A == cent)[0]]            centroids[cent, :] = np.mean(ptsInClust, axis=0)    return centroids, clusterAssment'''1、随机产生K个中心点（真实存在的、虚拟的)2、计算空间中到K个中心点的距离3、看一下空间中的样本离哪一个中心点最近4、归完类之后，我们要重新计算K个类的新的中心点(这个类所有样本的横纵坐标取均值)5、计算空间中的样本与新的K个中心点距离6、归类7、直到新的中心的坐标与上一次中心点的坐标不再发生改变'''if __name__ == '__main__':    dataMat = np.mat(loadDataSet('../data/testSet.txt'))  # 读取数据集，数据集为文本文件，每行一个样本，样本之间用tab分割，这里读取的数据是一个m*2的矩阵，每列分别代表样本的两个特征，这里m=80    k = 6  # 设置k值    '''    调用kmeans算法，进行聚类分析, 输入参数分别为数据集、k值、距离计算函数、初始中心点选择函数，distEclud计算欧氏距离，randCent随机生成初始中心点    得到聚类中心和聚类结果，clusterAssment是一个m*2的矩阵，第一列存储样本点所属的族的索引值，第二列存储该点与所属族的质心的平方误差    '''    centroids, clusterAssment = kMeans(dataMat, k, distMeas=distEclud, createCent=randCent)    print(clusterAssment)  # 打印聚类结果    print("-----------------")    print(centroids)  # 打印聚类中心    dataMat = np.array(dataMat)    y_pred1 = np.array([int(i) for j in clusterAssment[:, 0].A for i in j])    plt.subplot(224)    plt.scatter(dataMat[:, 0], dataMat[:, 1], c=y_pred1)    plt.title("kmeans04")    plt.show()